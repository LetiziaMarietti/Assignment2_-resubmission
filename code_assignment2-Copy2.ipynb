{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125043a-16bd-4434-9023-013cfaaf4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#install Italian language model\n",
    "!spacy download it_core_news_sm\n",
    "#install English language model\n",
    "!spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b95695-e305-4ce6-9b8e-16164f4ee463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os to upload documents and metadata\n",
    "import os\n",
    "\n",
    "# Load spaCy visualizer\n",
    "from spacy import displacy\n",
    "\n",
    "# Import pandas DataFrame packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Import graphing package\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8c90c9-dc75-4a73-af6c-719b253ed1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store Italian and English texts\n",
    "texts_it = []\n",
    "texts_en = []\n",
    "file_names_it = []\n",
    "file_names_en = []\n",
    "\n",
    "# Define paths to folders containing Italian and English texts \n",
    "folder_path_it = 'data_italian'\n",
    "folder_path_en = 'data_english'\n",
    "\n",
    "# Iterate through each file in the Italian texts folder\n",
    "for _file_name in os.listdir(folder_path_it):\n",
    "# Look for only text files\n",
    "    if _file_name.endswith('.txt'):\n",
    "    # Append contents of each text file to text list\n",
    "        texts_it.append(open(folder_path_it + '/' + _file_name, 'r', encoding='utf-8').read())\n",
    "        # Append name of each file to file name list\n",
    "        file_names_it.append(_file_name)\n",
    "\n",
    "# Iterate through each file in the English texts folder\n",
    "for _file_name in os.listdir(folder_path_en):\n",
    "# Look for only text files\n",
    "    if _file_name.endswith('.txt'):\n",
    "    # Append contents of each text file to text list\n",
    "        texts_en.append(open(folder_path_en + '/' + _file_name, 'r', encoding='utf-8').read())\n",
    "        # Append name of each file to file name list\n",
    "        file_names_en.append(_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a15c09c7-6444-45fa-a8e8-3b01408e9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary objects associating each file name with its text, one for Italian texts and one for English\n",
    "d_it = {'Filename':file_names_it,'Document':texts_it}\n",
    "d_en = {'Filename':file_names_en,'Document':texts_en}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24800399-38c3-4fee-b719-bb60573ba732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dictionaries into dataframes\n",
    "ungaretti_df = pd.DataFrame(d_it)\n",
    "warpoets_df = pd.DataFrame(d_en) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c30e9-bf0c-46a4-a625-f443c53d6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "ungaretti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcee51-4536-401f-a202-b7890987ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warpoets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138db97-6df3-45c0-b970-ea6a7a4eee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a preprocessed \"Text\" column\n",
    "ungaretti_df['Text'] = ungaretti_df['Document'].str.replace('[\\n\\u2028]', ' ', regex=True).str.strip()\n",
    "ungaretti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9169865-0c0d-473a-813a-4fc741479c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "warpoets_df['Text'] = warpoets_df['Document'].str.replace('[\\n\\u2028]', ' ', regex=True).str.strip()\n",
    "warpoets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098b275-7895-4525-90e1-567a89ba9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_en_df = pd.read_csv('extra_columns_en.csv')\n",
    "metadata_en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25fbec-213e-44a0-81ac-f4ab831b286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_it_df = pd.read_csv('extra_columns_it2.csv')\n",
    "metadata_it_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74099fa-0a2c-4f16-85ae-c6bd4a780fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge metadata and original DataFrames into a new, complete one \n",
    "final_ungaretti_df = metadata_it_df.merge(ungaretti_df,on='Filename')\n",
    "final_ungaretti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b3ce6-fd7b-40ad-ace4-e2ffe5fff820",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_warpoets_df = metadata_en_df.merge(warpoets_df,on='Filename')\n",
    "final_warpoets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2c78e-e2d2-4b00-9083-741431ff9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nlp pipeline\n",
    "nlp_it = spacy.load('it_core_news_sm')\n",
    "# Check what functions it performs\n",
    "print(nlp_it.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37237b8-1187-4f6d-be7c-bc12ea8a2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "print(nlp_en.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "386ddb02-e58c-4f17-b5d7-6f966364c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if code works \n",
    "sentence = \"This is 'an' example? sentence\"\n",
    "\n",
    "# Call the nlp model on the sentence\n",
    "doc = nlp_en(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52993b-f08b-4116-9d25-f59f741b5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each token in doc object\n",
    "for token in doc:\n",
    "    # Print text and part of speech for each\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5caf81b7-79c7-40cd-9865-f25da2447a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that runs the nlp pipeline on any given input text, one for each model\n",
    "def process_texts_it(text):\n",
    "    return nlp_it(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "29ec5326-75a2-458e-9699-1ca1c9eba30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the \"Text\" column, so that the nlp pipeline is called on each poem\n",
    "final_ungaretti_df['Text'] = final_ungaretti_df['Text'].apply(process_texts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e525e985-f0ba-4143-b7b8-1ba81ae344cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_texts_en(text):\n",
    "    return nlp_en(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8c58d85-369d-4c98-82e1-adaba766aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_warpoets_df['Text'] = final_warpoets_df['Text'].apply(process_texts_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7edb3033-f589-4d7c-84e1-5338765aa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve tokens from a doc object\n",
    "# (same for both English and Italian, as the process of tokenization is not language dependent)\n",
    "def get_token(doc):\n",
    "    return [(token.text) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8ab9a-524d-4ba0-8933-ae3be3fd06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the token retrieval function on the doc objects in the dataframe\n",
    "final_ungaretti_df['Tokens'] = final_ungaretti_df['Text'].apply(get_token)\n",
    "final_ungaretti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db740c2-d2b9-4b98-bb8d-0ee98922dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_warpoets_df['Tokens'] = final_warpoets_df['Text'].apply(get_token)\n",
    "final_warpoets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959d1fc-e7c4-4a14-bd87-3debda85ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = final_ungaretti_df[['Text', 'Tokens']].copy()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a72317db-ab18-475e-bac9-5fe4c01af22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve lemmas from a doc object, one for each model \n",
    "def get_lemma_it(text):\n",
    "    doc = nlp_it(text)\n",
    "    return [(token.lemma_) for token in doc]\n",
    "\n",
    "# Run the lemma retrieval function on the doc objects in the dataframe\n",
    "final_ungaretti_df['Lemmas'] = final_ungaretti_df['Text'].apply(get_lemma_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "981c3276-be96-44d6-89bc-f593eea81b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_en(text):\n",
    "    doc = nlp_en(text)\n",
    "    return [(token.lemma_) for token in doc]\n",
    "\n",
    "# Run the lemma retrieval function on the doc objects in the dataframe\n",
    "final_warpoets_df['Lemmas'] = final_warpoets_df['Text'].apply(get_lemma_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf648ca-939b-434f-b434-880904f1f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\"pietra\" appears in the text tokens column ' + str(final_ungaretti_df['Tokens'].apply(lambda x: x.count('pietra')).sum()) + ' times.')\n",
    "print(f'\"pietra\" appears in the lemmas column ' + str(final_ungaretti_df['Lemmas'].apply(lambda x: x.count('pietra')).sum()) + ' times.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "50e42001-66ab-452e-9e76-5cdcf41a3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve parts of speech from a doc object (same for both English and Italian)\n",
    "def get_pos(doc):\n",
    "    #Return the coarse- and fine-grained part of speech text for each token in the doc\n",
    "    return [(token.pos_, token.tag_) for token in doc]\n",
    "\n",
    "# Run the parts of speech retrieval function on the doc objects in the dataframe\n",
    "final_ungaretti_df['POS'] = final_ungaretti_df['Text'].apply(get_pos)\n",
    "final_warpoets_df['POS'] = final_warpoets_df['Text'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983d401-6d81-4576-9a09-a43f8d1a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of part of speech tags\n",
    "list(final_ungaretti_df['POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbf1e3-3b9f-4682-9de3-a622985ff83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(final_warpoets_df['POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951193eb-4989-4e81-9181-ed9d5263f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all NE labels and assign to variable, for both language models\n",
    "labels_it = nlp_it.get_pipe(\"ner\").labels\n",
    "\n",
    "# Print each label and its description\n",
    "for label in labels_it:\n",
    "    print(label + ' : ' + spacy.explain(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c6a5b-6c74-4d27-9eb7-0c268480bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_en = nlp_en.get_pipe(\"ner\").labels\n",
    "\n",
    "# Print each label and its description\n",
    "for label in labels_en:\n",
    "    print(label + ' : ' + spacy.explain(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219767b-9d59-413f-bf5d-a79dcaa016e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract named entities from doc objects, one for each model \n",
    "def extract_named_entities_it(text):\n",
    "    doc = nlp_it(text)\n",
    "    return [ent.label_ for ent in doc.ents]\n",
    "\n",
    "# Apply function to Doc column and store resulting named entities in new column\n",
    "final_ungaretti_df['Named_Entities'] = final_ungaretti_df['Text'].apply(extract_named_entities_it)\n",
    "final_ungaretti_df['Named_Entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11c9d2-53ae-4820-bee7-820e24aa7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities_en(text):\n",
    "    doc = nlp_en(text)\n",
    "    return [ent.label_ for ent in doc.ents]\n",
    "\n",
    "final_warpoets_df['Named_Entities'] = final_warpoets_df['Text'].apply(extract_named_entities_en)\n",
    "final_warpoets_df['Named_Entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174599c1-a4ad-41a2-976f-d31b2c19af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract text tagged with named entities from doc objects, one for each model \n",
    "def extract_named_entities_it(text):\n",
    "    doc = nlp_it(text)\n",
    "    return [ent for ent in doc.ents]\n",
    "\n",
    "# Apply function to Doc column and store resulting text in new column\n",
    "final_ungaretti_df['NE_Words'] = final_ungaretti_df['Text'].apply(extract_named_entities_it)\n",
    "final_ungaretti_df['NE_Words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857b03a-d467-4dfe-882d-2b2de082619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities_en(text):\n",
    "    doc = nlp_en(text)\n",
    "    return [ent for ent in doc.ents]\n",
    "\n",
    "# Apply function to Doc column and store resulting text in new column\n",
    "final_warpoets_df['NE_Words'] = final_warpoets_df['Text'].apply(extract_named_entities_en)\n",
    "final_warpoets_df['NE_Words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b33d16db-da08-4731-91d6-6299ab2fd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "final_df = pd.concat([final_ungaretti_df, final_warpoets_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "84522ea1-b656-4e20-ab28-8d3d7c997178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn DataFrame into .csv file\n",
    "final_df.to_csv('war_poems.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
